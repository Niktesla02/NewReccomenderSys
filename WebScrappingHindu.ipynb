{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tr2vMvkkf85A"
   },
   "outputs": [],
   "source": [
    "#importing the required packages\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date,timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lo099cfwgxCr"
   },
   "outputs": [],
   "source": [
    "def retrieving_information_for_the_day(year,month,day): \n",
    "    # iterate the dates to get news from these dates\n",
    "    web_url= \"https://www.thehindu.com/archive/web/\"+str(year)+\"/\"+str(month)+\"/\"+str(day)+\"/\"\n",
    "    #getting html source code from the url\n",
    "    raw_data=requests.get(web_url,'lxml')\n",
    "    #We create a Beautiful soup object and use it to find the required information from the url\n",
    "    soup=bs(raw_data.content,'html5lib')\n",
    "    information=soup.findAll('ul',class_='archive-list')\n",
    "    return information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8nmdGquChw_F"
   },
   "outputs": [],
   "source": [
    "#the headlines from the day\n",
    "def news(information):\n",
    "    news=[]\n",
    "    for i in range(len(information)):\n",
    "        for j in range(len(information[i].findAll('a'))):\n",
    "              news.append(information[i].findAll('a')[j])\n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tiidCCaAh7Na"
   },
   "outputs": [],
   "source": [
    "#this is a function to scrap the title of the news and the link to the main content from the information\n",
    "def news_links(headlines):\n",
    "    links=[]\n",
    "    for i in range(len(headlines)):\n",
    "        links.append(headlines[i]['href'])\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sQOnQAirjtCY"
   },
   "outputs": [],
   "source": [
    "#this function scraps the authors of the articles and  identifies the articles with no authors.\n",
    "#These articles are then removed.\n",
    "def news_authors(links):\n",
    "    authors=[]\n",
    "    noauthors=[]\n",
    "    c=0\n",
    "    for i in range(len(links)):\n",
    "        content_data=requests.get(links[i],'lxml')\n",
    "        soup1=bs(content_data.content,'html5lib')\n",
    "        author=soup1.find('a',{\"class\":[\"auth-nm lnk\",\"auth-nm no-lnk\"]})\n",
    "        if author!=None:\n",
    "            authors.append(author.get_text().strip('\\n'))\n",
    "        if author==None:\n",
    "            noauthors.append(i)\n",
    "            authors.append(0)\n",
    "    return authors,noauthors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(authors,noauthors,links,headlines):\n",
    "    c=0\n",
    "    for i in noauthors:\n",
    "        authors.remove(authors[i-c])\n",
    "        links.remove(links[i-c])\n",
    "        headlines.remove(headlines[i-c])\n",
    "        c=c+1\n",
    "    return authors,links,headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a function to scrap the title of the news and the link to the main content from the information\n",
    "def newstitles(headlines):\n",
    "    news_titles=[]\n",
    "    for i in range(len(headlines)):\n",
    "        news_titles.append(headlines[i].get_text())\n",
    "    return news_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function finds the date and time of publishing of the article.\n",
    "def date_and_time(links):\n",
    "    date=[]\n",
    "    time=[]\n",
    "    for i in range(len(links)):\n",
    "        content_data=requests.get(links[i],'lxml')\n",
    "        soup1=bs(content_data.content,'html5lib')\n",
    "        when=soup1.find('meta',{\"name\":\"publish-date\"})\n",
    "        date_and_time=when['content'].split('T')\n",
    "        date.append(date_and_time[0])\n",
    "        time.append(date_and_time[1].replace(\"+05:30\",\" IST\"))\n",
    "    return date,time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qoCPvV8miH8B"
   },
   "outputs": [],
   "source": [
    "#this function goes to the links of the headines and gets the full content\n",
    "def retrieving_news_content(links):\n",
    "    news_contents=[]\n",
    "    for i in range(len(links)):\n",
    "        content_data=requests.get(links[i],'lxml')\n",
    "        soup1=bs(content_data.content,'html5lib')\n",
    "        raw_content=soup1.findAll('p',class_=\"\")\n",
    "        paragraph=''\n",
    "        for j in range(len(raw_content)):\n",
    "            if len(raw_content[j].get_text())>10:\n",
    "                paragraph+=raw_content[j].get_text()\n",
    "        news_contents.append(paragraph.strip('\\n').split(\"Start your 14 days trial now.\")[0])\n",
    "    return news_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the dates to increase the number of articles scrapped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_links=[]\n",
    "all_news_titles=[]\n",
    "all_authors=[]\n",
    "all_noauthors=[]\n",
    "all_news_contents=[]\n",
    "all_dates=[]\n",
    "all_times=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the start and end date for news articles in yyyy-mm-dd format.\n",
    "start_date=date(2010,5,7)\n",
    "end_date=date(2010,5,8)\n",
    "time_difference=(end_date-start_date).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UDBEIJqC36Gr"
   },
   "outputs": [],
   "source": [
    "#This is the function to retrieve the articles and make a corpus.\n",
    "def news_articles(time_difference):\n",
    "    for i in range(0,time_difference):\n",
    "        year=(start_date+timedelta(i)).year\n",
    "        month=(start_date+timedelta(i)).month\n",
    "        day=(start_date+timedelta(i)).day\n",
    "        information=retrieving_information_for_the_day(year,month,day)\n",
    "        headlines=news(information)\n",
    "        links=news_links(headlines)\n",
    "        authors,noauthors=news_authors(links)\n",
    "        authors,links,headlines=processing(authors,noauthors,links,headlines)\n",
    "        all_authors.extend(authors)\n",
    "        all_links.extend(links)\n",
    "        news_titles=newstitles(headlines)\n",
    "        all_news_titles.extend(news_titles)\n",
    "        date,time=date_and_time(links)\n",
    "        all_dates.extend(date)\n",
    "        all_times.extend(time)\n",
    "        news_contents=retrieving_news_content(links)\n",
    "        all_news_contents.extend(news_contents)\n",
    "    return all_links,all_news_titles,all_authors,all_news_contents,all_dates,all_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could take a long enough time span for making the corpus\n",
    "#or we could take short steps of 5 days each and make a large corpus\n",
    "all_links,all_news_titles,all_authors,all_news_contents,all_dates,all_times=news_articles(time_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In case you are making the corpus step by step\n",
    "all_links.extend(all_links)\n",
    "all_news_titles.extend(all_news_titles)\n",
    "all_authors.extend(all_authors)\n",
    "all_news_contents.extend(all_news_contents)\n",
    "all_dates.extend(all_dates)\n",
    "all_times.extend(all_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'news titles':all_news_titles,'author':all_authors,'date':all_dates,'time':all_times,'content':all_news_contents,'links':all_links}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news titles</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>content</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Second Thoughts: Come with old Khayyam</td>\n",
       "      <td>NAVTEJ SARNA</td>\n",
       "      <td>2010-05-06</td>\n",
       "      <td>18:56:53 IST</td>\n",
       "      <td>The other day, halfway through a virtual conve...</td>\n",
       "      <td>https://www.thehindu.com/opinion/columns/navte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Mystery Knight bags feature</td>\n",
       "      <td>Racing Correspondent</td>\n",
       "      <td>2010-05-06</td>\n",
       "      <td>16:52:09 IST</td>\n",
       "      <td>Mr.M.A.M.R.Muthiah’s Mystery Knight (Manikanda...</td>\n",
       "      <td>https://www.thehindu.com/sport/races/Mystery-K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Sky Drive shows out</td>\n",
       "      <td>Racing Correspondent</td>\n",
       "      <td>2010-05-06</td>\n",
       "      <td>14:45:21 IST</td>\n",
       "      <td>Sky Drive, Cumulus Nimbus, Stormyred and Athab...</td>\n",
       "      <td>https://www.thehindu.com/sport/races/Sky-Drive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Staging a change</td>\n",
       "      <td>SANGEETA BAROOAH PISHAROTY</td>\n",
       "      <td>2010-05-06</td>\n",
       "      <td>17:10:30 IST</td>\n",
       "      <td>Sitanath Lahkar has made his passion blossom. ...</td>\n",
       "      <td>https://www.thehindu.com/features/friday-revie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>In Ghalib's skin</td>\n",
       "      <td>DIWAN SINGH BAJELI</td>\n",
       "      <td>2010-05-06</td>\n",
       "      <td>16:49:22 IST</td>\n",
       "      <td>“In recent years, we have seen several plays a...</td>\n",
       "      <td>https://www.thehindu.com/features/friday-revie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1395</td>\n",
       "      <td>Carbon black plant opposed</td>\n",
       "      <td>Special Correspondent</td>\n",
       "      <td>2010-05-07</td>\n",
       "      <td>00:19:55 IST</td>\n",
       "      <td>Almost all those who attended the environmenta...</td>\n",
       "      <td>https://www.thehindu.com/news/cities/Visakhapa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1396</td>\n",
       "      <td>Kuchipudi dance team floored by response in US</td>\n",
       "      <td>Staff Reporter</td>\n",
       "      <td>2010-05-07</td>\n",
       "      <td>00:17:55 IST</td>\n",
       "      <td>Presdent of Rotary Club Elite Ali speaking at ...</td>\n",
       "      <td>https://www.thehindu.com/news/cities/Visakhapa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1397</td>\n",
       "      <td>Chill with apricots</td>\n",
       "      <td>Chef NARAYAN RAO</td>\n",
       "      <td>2010-05-07</td>\n",
       "      <td>20:19:39 IST</td>\n",
       "      <td>Khubani Ka Meetha at AMAN Hotel, New Delhi. Ph...</td>\n",
       "      <td>https://www.thehindu.com/life-and-style/Chill-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1398</td>\n",
       "      <td>Vettel sets pace in Spain</td>\n",
       "      <td>DPA</td>\n",
       "      <td>2010-05-07</td>\n",
       "      <td>20:24:36 IST</td>\n",
       "      <td>Red Bull F1 driver Sebastian Vettel\\n  The Red...</td>\n",
       "      <td>https://www.thehindu.com/sport/motorsport/Vett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1399</td>\n",
       "      <td>Call to protect monuments</td>\n",
       "      <td>Special Correspondent</td>\n",
       "      <td>2010-05-07</td>\n",
       "      <td>02:19:07 IST</td>\n",
       "      <td>GENERATING AWARENESS: School Education Minster...</td>\n",
       "      <td>https://www.thehindu.com/features/friday-revie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         news titles  \\\n",
       "0            Second Thoughts: Come with old Khayyam    \n",
       "1                        Mystery Knight bags feature   \n",
       "2                                Sky Drive shows out   \n",
       "3                                   Staging a change   \n",
       "4                                   In Ghalib's skin   \n",
       "...                                              ...   \n",
       "1395                      Carbon black plant opposed   \n",
       "1396  Kuchipudi dance team floored by response in US   \n",
       "1397                             Chill with apricots   \n",
       "1398                       Vettel sets pace in Spain   \n",
       "1399                       Call to protect monuments   \n",
       "\n",
       "                          author        date          time  \\\n",
       "0                   NAVTEJ SARNA  2010-05-06  18:56:53 IST   \n",
       "1           Racing Correspondent  2010-05-06  16:52:09 IST   \n",
       "2           Racing Correspondent  2010-05-06  14:45:21 IST   \n",
       "3     SANGEETA BAROOAH PISHAROTY  2010-05-06  17:10:30 IST   \n",
       "4             DIWAN SINGH BAJELI  2010-05-06  16:49:22 IST   \n",
       "...                          ...         ...           ...   \n",
       "1395       Special Correspondent  2010-05-07  00:19:55 IST   \n",
       "1396              Staff Reporter  2010-05-07  00:17:55 IST   \n",
       "1397            Chef NARAYAN RAO  2010-05-07  20:19:39 IST   \n",
       "1398                         DPA  2010-05-07  20:24:36 IST   \n",
       "1399       Special Correspondent  2010-05-07  02:19:07 IST   \n",
       "\n",
       "                                                content  \\\n",
       "0     The other day, halfway through a virtual conve...   \n",
       "1     Mr.M.A.M.R.Muthiah’s Mystery Knight (Manikanda...   \n",
       "2     Sky Drive, Cumulus Nimbus, Stormyred and Athab...   \n",
       "3     Sitanath Lahkar has made his passion blossom. ...   \n",
       "4     “In recent years, we have seen several plays a...   \n",
       "...                                                 ...   \n",
       "1395  Almost all those who attended the environmenta...   \n",
       "1396  Presdent of Rotary Club Elite Ali speaking at ...   \n",
       "1397  Khubani Ka Meetha at AMAN Hotel, New Delhi. Ph...   \n",
       "1398  Red Bull F1 driver Sebastian Vettel\\n  The Red...   \n",
       "1399  GENERATING AWARENESS: School Education Minster...   \n",
       "\n",
       "                                                  links  \n",
       "0     https://www.thehindu.com/opinion/columns/navte...  \n",
       "1     https://www.thehindu.com/sport/races/Mystery-K...  \n",
       "2     https://www.thehindu.com/sport/races/Sky-Drive...  \n",
       "3     https://www.thehindu.com/features/friday-revie...  \n",
       "4     https://www.thehindu.com/features/friday-revie...  \n",
       "...                                                 ...  \n",
       "1395  https://www.thehindu.com/news/cities/Visakhapa...  \n",
       "1396  https://www.thehindu.com/news/cities/Visakhapa...  \n",
       "1397  https://www.thehindu.com/life-and-style/Chill-...  \n",
       "1398  https://www.thehindu.com/sport/motorsport/Vett...  \n",
       "1399  https://www.thehindu.com/features/friday-revie...  \n",
       "\n",
       "[1400 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus=pd.DataFrame(data)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.to_csv('corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPSPmBPA0pUAhARu0tKqvvF",
   "collapsed_sections": [],
   "name": "WebScrappingHindu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
